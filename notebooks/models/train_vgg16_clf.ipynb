{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25532,"status":"ok","timestamp":1672328425908,"user":{"displayName":"Tihomir Pavic","userId":"12556438120461886781"},"user_tz":-60},"id":"nFs3MGR7eYDW","outputId":"b2b04270-4dc7-4fa3-f105-6276d80cc8bf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1pNDXgXifSjX"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras import layers\n","from tensorflow.keras import Model\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import cv2 as cv\n","from tensorflow.keras.applications.vgg16 import VGG16\n","from sklearn import metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":4824,"status":"ok","timestamp":1672328438373,"user":{"displayName":"Tihomir Pavic","userId":"12556438120461886781"},"user_tz":-60},"id":"Y-1aGO2bgRr5","outputId":"21e1d61b-b5df-4847-a7bd-4420e26620b2"},"outputs":[],"source":["train_df = pd.read_csv('/content/gdrive/MyDrive/asub_dataset/preprocessed_newest/train.csv')\n","valid_df = pd.read_csv('/content/gdrive/MyDrive/asub_dataset/preprocessed_newest/validation.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zXM1GuqMjWXC"},"outputs":[],"source":["# ucitavanje skupa podataka\n","X_train = []\n","y_train = []\n","for i in range(len(train_df)):\n","    img = cv.imread(train_df['path'][i])\n","\n","    X_train.append(np.array(img))\n","    y_train.append(train_df['label'][i])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t5fctkYQl9TC"},"outputs":[],"source":["# ucitavanje skupa podataka\n","X_validation = []\n","y_validation = []\n","for i in range(len(valid_df)):\n","    img = cv.imread(valid_df['path'][i])\n","\n","    X_validation.append(np.array(img))\n","    y_validation.append(valid_df['label'][i])\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iuu8FFJtoFP3"},"outputs":[],"source":["# pretvorba u numpy array\n","\n","X_train = np.array(X_train)\n","X_validation = np.array(X_validation)\n","\n","y_train = np.array(y_train)\n","y_validation = np.array(y_validation)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":430,"status":"ok","timestamp":1672331875899,"user":{"displayName":"Tihomir Pavic","userId":"12556438120461886781"},"user_tz":-60},"id":"SryLaZCKn6M-","outputId":"fe454bed-42a2-417f-8c24-39c6d4916197"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape X_train: (1920, 200, 200, 3)\n","Shape X_validation: (480, 200, 200, 3)\n","Shape X_test: (600, 200, 200, 3)\n","Shape y_train: (1920,)\n","Shape y_validation: (480,)\n","Shape y_test: (600,)\n"]}],"source":["#provjera dimenzija\n","\n","print(\"Shape X_train: {0}\".format(X_train.shape))\n","print(\"Shape X_validation: {0}\".format(X_validation.shape))\n","print(\"Shape y_train: {0}\".format(y_train.shape))\n","print(\"Shape y_validation: {0}\".format(y_validation.shape))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9vwya-6Uq2tV"},"outputs":[],"source":["#normalizacija\n","train_x = tf.keras.utils.normalize(X_train, axis=1)\n","validation_x = tf.keras.utils.normalize(X_validation, axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vaGfJhYgzuau"},"outputs":[],"source":["######## model\n","# definiramo callback funkcije koje pomazu kod procesa ucenja\n","# ReduceLROnPlateau cemo koristiti umjesto da optimiramo hiperparametar stope ucenja\n","# ako u 2 epohe nismo dobili bolji validation loss, smanjujemo za lr za definirani faktor\n","\n","reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n","    monitor='val_loss',\n","    factor=0.2,\n","    patience=3,\n","    min_lr=1e-9,\n","    verbose=1\n",")\n","\n","# ovo je callback koji omogućuje spremanje modela ovisno o accuracyu na validation setu\n","checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath='/content/gdrive/MyDrive/asub_dataset/colab - biljeznice/vgg16-model/best_model',\n","    monitor='val_acc',\n","    save_best_only=True,\n","    verbose=1\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1435826,"status":"ok","timestamp":1672333906634,"user":{"displayName":"Tihomir Pavic","userId":"12556438120461886781"},"user_tz":-60},"id":"crp4VYZLD5y1","outputId":"63f1a549-1668-4d3d-dc12-8f13216e66a8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Batch size: 16\n","\n","Epoch 1/40\n","120/120 [==============================] - ETA: 0s - loss: 0.6645 - acc: 0.6938\n","Epoch 1: val_acc improved from -inf to 0.87500, saving model to /content/gdrive/MyDrive/asub_dataset/colab - biljeznice/vgg16-model/best model-optimization\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r120/120 [==============================] - 14s 114ms/step - loss: 0.6645 - acc: 0.6938 - val_loss: 0.3551 - val_acc: 0.8750 - lr: 0.0010\n","Epoch 2/40\n","120/120 [==============================] - ETA: 0s - loss: 0.3619 - acc: 0.8495\n","Epoch 2: val_acc improved from 0.87500 to 0.91042, saving model to /content/gdrive/MyDrive/asub_dataset/colab - biljeznice/vgg16-model/best model-optimization\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r120/120 [==============================] - 13s 105ms/step - loss: 0.3619 - acc: 0.8495 - val_loss: 0.2821 - val_acc: 0.9104 - lr: 0.0010\n","Epoch 3/40\n","120/120 [==============================] - ETA: 0s - loss: 0.3124 - acc: 0.8745\n","Epoch 3: val_acc improved from 0.91042 to 0.91667, saving model to /content/gdrive/MyDrive/asub_dataset/colab - biljeznice/vgg16-model/best model-optimization\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r120/120 [==============================] - 13s 107ms/step - loss: 0.3124 - acc: 0.8745 - val_loss: 0.2557 - val_acc: 0.9167 - lr: 0.0010\n","Epoch 4/40\n","120/120 [==============================] - ETA: 0s - loss: 0.2536 - acc: 0.8927\n","Epoch 4: val_acc did not improve from 0.91667\n","120/120 [==============================] - 11s 91ms/step - loss: 0.2536 - acc: 0.8927 - val_loss: 0.3160 - val_acc: 0.8625 - lr: 0.0010\n","Epoch 5/40\n","120/120 [==============================] - ETA: 0s - loss: 0.2300 - acc: 0.9104\n","Epoch 5: val_acc did not improve from 0.91667\n","120/120 [==============================] - 11s 94ms/step - loss: 0.2300 - acc: 0.9104 - val_loss: 0.2481 - val_acc: 0.9021 - lr: 0.0010\n","Epoch 6/40\n","120/120 [==============================] - ETA: 0s - loss: 0.2198 - acc: 0.9073\n","Epoch 6: val_acc improved from 0.91667 to 0.94167, saving model to /content/gdrive/MyDrive/asub_dataset/colab - biljeznice/vgg16-model/best model-optimization\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r120/120 [==============================] - 14s 116ms/step - loss: 0.2198 - acc: 0.9073 - val_loss: 0.1945 - val_acc: 0.9417 - lr: 0.0010\n","Epoch 7/40\n","120/120 [==============================] - ETA: 0s - loss: 0.2307 - acc: 0.9000\n","Epoch 7: val_acc did not improve from 0.94167\n","120/120 [==============================] - 11s 96ms/step - loss: 0.2307 - acc: 0.9000 - val_loss: 0.5868 - val_acc: 0.7375 - lr: 0.0010\n","Epoch 8/40\n","120/120 [==============================] - ETA: 0s - loss: 0.1933 - acc: 0.9245\n","Epoch 8: val_acc did not improve from 0.94167\n","120/120 [==============================] - 12s 97ms/step - loss: 0.1933 - acc: 0.9245 - val_loss: 0.4764 - val_acc: 0.7896 - lr: 0.0010\n","Epoch 9/40\n","120/120 [==============================] - ETA: 0s - loss: 0.1443 - acc: 0.9422\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n","\n","Epoch 9: val_acc did not improve from 0.94167\n","120/120 [==============================] - 12s 98ms/step - loss: 0.1443 - acc: 0.9422 - val_loss: 0.2513 - val_acc: 0.9021 - lr: 0.0010\n","Epoch 10/40\n","120/120 [==============================] - ETA: 0s - loss: 0.1036 - acc: 0.9641\n","Epoch 10: val_acc did not improve from 0.94167\n","120/120 [==============================] - 12s 100ms/step - loss: 0.1036 - acc: 0.9641 - val_loss: 0.1882 - val_acc: 0.9292 - lr: 2.0000e-04\n","Epoch 11/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0945 - acc: 0.9729\n","Epoch 11: val_acc improved from 0.94167 to 0.94583, saving model to /content/gdrive/MyDrive/asub_dataset/colab - biljeznice/vgg16-model/best model-optimization\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r120/120 [==============================] - 14s 115ms/step - loss: 0.0945 - acc: 0.9729 - val_loss: 0.1570 - val_acc: 0.9458 - lr: 2.0000e-04\n","Epoch 12/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0985 - acc: 0.9677\n","Epoch 12: val_acc did not improve from 0.94583\n","120/120 [==============================] - 12s 98ms/step - loss: 0.0985 - acc: 0.9677 - val_loss: 0.1719 - val_acc: 0.9396 - lr: 2.0000e-04\n","Epoch 13/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0876 - acc: 0.9786\n","Epoch 13: val_acc improved from 0.94583 to 0.95833, saving model to /content/gdrive/MyDrive/asub_dataset/colab - biljeznice/vgg16-model/best model-optimization\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r120/120 [==============================] - 14s 115ms/step - loss: 0.0876 - acc: 0.9786 - val_loss: 0.1486 - val_acc: 0.9583 - lr: 2.0000e-04\n","Epoch 14/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0824 - acc: 0.9729\n","Epoch 14: val_acc did not improve from 0.95833\n","120/120 [==============================] - 11s 95ms/step - loss: 0.0824 - acc: 0.9729 - val_loss: 0.1631 - val_acc: 0.9375 - lr: 2.0000e-04\n","Epoch 15/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0911 - acc: 0.9677\n","Epoch 15: val_acc did not improve from 0.95833\n","120/120 [==============================] - 11s 96ms/step - loss: 0.0911 - acc: 0.9677 - val_loss: 0.1465 - val_acc: 0.9542 - lr: 2.0000e-04\n","Epoch 16/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0782 - acc: 0.9760\n","Epoch 16: val_acc did not improve from 0.95833\n","120/120 [==============================] - 12s 99ms/step - loss: 0.0782 - acc: 0.9760 - val_loss: 0.1432 - val_acc: 0.9521 - lr: 2.0000e-04\n","Epoch 17/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0851 - acc: 0.9708\n","Epoch 17: val_acc did not improve from 0.95833\n","120/120 [==============================] - 12s 97ms/step - loss: 0.0851 - acc: 0.9708 - val_loss: 0.1419 - val_acc: 0.9521 - lr: 2.0000e-04\n","Epoch 18/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0962 - acc: 0.9661\n","Epoch 18: val_acc did not improve from 0.95833\n","120/120 [==============================] - 12s 98ms/step - loss: 0.0962 - acc: 0.9661 - val_loss: 0.1635 - val_acc: 0.9396 - lr: 2.0000e-04\n","Epoch 19/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0726 - acc: 0.9781\n","Epoch 19: val_acc did not improve from 0.95833\n","120/120 [==============================] - 11s 95ms/step - loss: 0.0726 - acc: 0.9781 - val_loss: 0.1507 - val_acc: 0.9542 - lr: 2.0000e-04\n","Epoch 20/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0715 - acc: 0.9766\n","Epoch 20: val_acc did not improve from 0.95833\n","120/120 [==============================] - 12s 98ms/step - loss: 0.0715 - acc: 0.9766 - val_loss: 0.1365 - val_acc: 0.9542 - lr: 2.0000e-04\n","Epoch 21/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0785 - acc: 0.9740\n","Epoch 21: val_acc did not improve from 0.95833\n","120/120 [==============================] - 12s 98ms/step - loss: 0.0785 - acc: 0.9740 - val_loss: 0.1411 - val_acc: 0.9521 - lr: 2.0000e-04\n","Epoch 22/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0744 - acc: 0.9781\n","Epoch 22: val_acc did not improve from 0.95833\n","120/120 [==============================] - 11s 95ms/step - loss: 0.0744 - acc: 0.9781 - val_loss: 0.1439 - val_acc: 0.9521 - lr: 2.0000e-04\n","Epoch 23/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0625 - acc: 0.9792\n","Epoch 23: val_acc did not improve from 0.95833\n","120/120 [==============================] - 12s 98ms/step - loss: 0.0625 - acc: 0.9792 - val_loss: 0.1340 - val_acc: 0.9542 - lr: 2.0000e-04\n","Epoch 24/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0841 - acc: 0.9729\n","Epoch 24: val_acc did not improve from 0.95833\n","120/120 [==============================] - 11s 96ms/step - loss: 0.0841 - acc: 0.9729 - val_loss: 0.1423 - val_acc: 0.9542 - lr: 2.0000e-04\n","Epoch 25/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0600 - acc: 0.9818\n","Epoch 25: val_acc did not improve from 0.95833\n","120/120 [==============================] - 12s 96ms/step - loss: 0.0600 - acc: 0.9818 - val_loss: 0.1603 - val_acc: 0.9438 - lr: 2.0000e-04\n","Epoch 26/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0618 - acc: 0.9802\n","Epoch 26: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n","\n","Epoch 26: val_acc did not improve from 0.95833\n","120/120 [==============================] - 12s 96ms/step - loss: 0.0618 - acc: 0.9802 - val_loss: 0.1350 - val_acc: 0.9583 - lr: 2.0000e-04\n","Epoch 27/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0520 - acc: 0.9865\n","Epoch 27: val_acc improved from 0.95833 to 0.96042, saving model to /content/gdrive/MyDrive/asub_dataset/colab - biljeznice/vgg16-model/best model-optimization\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r120/120 [==============================] - 14s 116ms/step - loss: 0.0520 - acc: 0.9865 - val_loss: 0.1305 - val_acc: 0.9604 - lr: 4.0000e-05\n","Epoch 28/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0457 - acc: 0.9885\n","Epoch 28: val_acc improved from 0.96042 to 0.96250, saving model to /content/gdrive/MyDrive/asub_dataset/colab - biljeznice/vgg16-model/best model-optimization\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r120/120 [==============================] - 14s 114ms/step - loss: 0.0457 - acc: 0.9885 - val_loss: 0.1291 - val_acc: 0.9625 - lr: 4.0000e-05\n","Epoch 29/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0444 - acc: 0.9880\n","Epoch 29: val_acc did not improve from 0.96250\n","120/120 [==============================] - 12s 98ms/step - loss: 0.0444 - acc: 0.9880 - val_loss: 0.1286 - val_acc: 0.9625 - lr: 4.0000e-05\n","Epoch 30/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0469 - acc: 0.9870\n","Epoch 30: val_acc did not improve from 0.96250\n","120/120 [==============================] - 12s 98ms/step - loss: 0.0469 - acc: 0.9870 - val_loss: 0.1571 - val_acc: 0.9458 - lr: 4.0000e-05\n","Epoch 31/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0453 - acc: 0.9880\n","Epoch 31: val_acc did not improve from 0.96250\n","120/120 [==============================] - 12s 99ms/step - loss: 0.0453 - acc: 0.9880 - val_loss: 0.1348 - val_acc: 0.9563 - lr: 4.0000e-05\n","Epoch 32/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0461 - acc: 0.9870\n","Epoch 32: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n","\n","Epoch 32: val_acc did not improve from 0.96250\n","120/120 [==============================] - 12s 99ms/step - loss: 0.0461 - acc: 0.9870 - val_loss: 0.1454 - val_acc: 0.9521 - lr: 4.0000e-05\n","Epoch 33/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0438 - acc: 0.9911\n","Epoch 33: val_acc did not improve from 0.96250\n","120/120 [==============================] - 12s 99ms/step - loss: 0.0438 - acc: 0.9911 - val_loss: 0.1337 - val_acc: 0.9583 - lr: 8.0000e-06\n","Epoch 34/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0487 - acc: 0.9875\n","Epoch 34: val_acc did not improve from 0.96250\n","120/120 [==============================] - 11s 96ms/step - loss: 0.0487 - acc: 0.9875 - val_loss: 0.1349 - val_acc: 0.9563 - lr: 8.0000e-06\n","Epoch 35/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0477 - acc: 0.9875\n","Epoch 35: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n","\n","Epoch 35: val_acc did not improve from 0.96250\n","120/120 [==============================] - 11s 95ms/step - loss: 0.0477 - acc: 0.9875 - val_loss: 0.1300 - val_acc: 0.9604 - lr: 8.0000e-06\n","Epoch 36/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0433 - acc: 0.9911\n","Epoch 36: val_acc did not improve from 0.96250\n","120/120 [==============================] - 12s 98ms/step - loss: 0.0433 - acc: 0.9911 - val_loss: 0.1343 - val_acc: 0.9563 - lr: 1.6000e-06\n","Epoch 37/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0415 - acc: 0.9922\n","Epoch 37: val_acc did not improve from 0.96250\n","120/120 [==============================] - 11s 95ms/step - loss: 0.0415 - acc: 0.9922 - val_loss: 0.1358 - val_acc: 0.9563 - lr: 1.6000e-06\n","Epoch 38/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0445 - acc: 0.9880\n","Epoch 38: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n","\n","Epoch 38: val_acc did not improve from 0.96250\n","120/120 [==============================] - 12s 98ms/step - loss: 0.0445 - acc: 0.9880 - val_loss: 0.1350 - val_acc: 0.9563 - lr: 1.6000e-06\n","Epoch 39/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0451 - acc: 0.9901\n","Epoch 39: val_acc did not improve from 0.96250\n","120/120 [==============================] - 12s 98ms/step - loss: 0.0451 - acc: 0.9901 - val_loss: 0.1356 - val_acc: 0.9563 - lr: 3.2000e-07\n","Epoch 40/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0473 - acc: 0.9875\n","Epoch 40: val_acc did not improve from 0.96250\n","120/120 [==============================] - 11s 95ms/step - loss: 0.0473 - acc: 0.9875 - val_loss: 0.1355 - val_acc: 0.9563 - lr: 3.2000e-07\n","Batch size: 32\n","\n","Epoch 1/40\n","60/60 [==============================] - ETA: 0s - loss: 0.9755 - acc: 0.6266\n","Epoch 1: val_acc did not improve from 0.96250\n","60/60 [==============================] - 15s 195ms/step - loss: 0.9755 - acc: 0.6266 - val_loss: 0.4902 - val_acc: 0.7729 - lr: 0.0010\n","Epoch 2/40\n","60/60 [==============================] - ETA: 0s - loss: 0.4412 - acc: 0.8031\n","Epoch 2: val_acc did not improve from 0.96250\n","60/60 [==============================] - 11s 185ms/step - loss: 0.4412 - acc: 0.8031 - val_loss: 0.3767 - val_acc: 0.8583 - lr: 0.0010\n","Epoch 3/40\n","60/60 [==============================] - ETA: 0s - loss: 0.3782 - acc: 0.8401\n","Epoch 3: val_acc did not improve from 0.96250\n","60/60 [==============================] - 11s 185ms/step - loss: 0.3782 - acc: 0.8401 - val_loss: 0.3191 - val_acc: 0.8896 - lr: 0.0010\n","Epoch 4/40\n","60/60 [==============================] - ETA: 0s - loss: 0.3095 - acc: 0.8755\n","Epoch 4: val_acc did not improve from 0.96250\n","60/60 [==============================] - 11s 191ms/step - loss: 0.3095 - acc: 0.8755 - val_loss: 0.2995 - val_acc: 0.8833 - lr: 0.0010\n","Epoch 5/40\n","60/60 [==============================] - ETA: 0s - loss: 0.2697 - acc: 0.8990\n","Epoch 5: val_acc did not improve from 0.96250\n","60/60 [==============================] - 11s 190ms/step - loss: 0.2697 - acc: 0.8990 - val_loss: 0.2535 - val_acc: 0.9187 - lr: 0.0010\n","Epoch 6/40\n","60/60 [==============================] - ETA: 0s - loss: 0.2503 - acc: 0.8990\n","Epoch 6: val_acc did not improve from 0.96250\n","60/60 [==============================] - 11s 184ms/step - loss: 0.2503 - acc: 0.8990 - val_loss: 0.2661 - val_acc: 0.9083 - lr: 0.0010\n","Epoch 7/40\n","60/60 [==============================] - ETA: 0s - loss: 0.2221 - acc: 0.9208\n","Epoch 7: val_acc did not improve from 0.96250\n","60/60 [==============================] - 11s 190ms/step - loss: 0.2221 - acc: 0.9208 - val_loss: 0.2776 - val_acc: 0.8896 - lr: 0.0010\n","Epoch 8/40\n","60/60 [==============================] - ETA: 0s - loss: 0.1991 - acc: 0.9297\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n","\n","Epoch 8: val_acc did not improve from 0.96250\n","60/60 [==============================] - 11s 184ms/step - loss: 0.1991 - acc: 0.9297 - val_loss: 0.3277 - val_acc: 0.8438 - lr: 0.0010\n","Epoch 9/40\n","60/60 [==============================] - ETA: 0s - loss: 0.1557 - acc: 0.9536\n","Epoch 9: val_acc did not improve from 0.96250\n","60/60 [==============================] - 11s 190ms/step - loss: 0.1557 - acc: 0.9536 - val_loss: 0.1982 - val_acc: 0.9312 - lr: 2.0000e-04\n","Epoch 10/40\n","60/60 [==============================] - ETA: 0s - loss: 0.1402 - acc: 0.9635\n","Epoch 10: val_acc did not improve from 0.96250\n","60/60 [==============================] - 11s 184ms/step - loss: 0.1402 - acc: 0.9635 - val_loss: 0.1960 - val_acc: 0.9292 - lr: 2.0000e-04\n","Epoch 11/40\n","60/60 [==============================] - ETA: 0s - loss: 0.1406 - acc: 0.9573\n","Epoch 11: val_acc did not improve from 0.96250\n","60/60 [==============================] - 11s 190ms/step - loss: 0.1406 - acc: 0.9573 - val_loss: 0.1868 - val_acc: 0.9438 - lr: 2.0000e-04\n","Epoch 12/40\n","60/60 [==============================] - ETA: 0s - loss: 0.1313 - acc: 0.9630\n","Epoch 12: val_acc did not improve from 0.96250\n","60/60 [==============================] - 11s 185ms/step - loss: 0.1313 - acc: 0.9630 - val_loss: 0.1849 - val_acc: 0.9417 - lr: 2.0000e-04\n","Epoch 13/40\n","60/60 [==============================] - ETA: 0s - loss: 0.1354 - acc: 0.9615\n","Epoch 13: val_acc did not improve from 0.96250\n","60/60 [==============================] - 11s 191ms/step - loss: 0.1354 - acc: 0.9615 - val_loss: 0.1807 - val_acc: 0.9438 - lr: 2.0000e-04\n","Epoch 14/40\n","60/60 [==============================] - ETA: 0s - loss: 0.1323 - acc: 0.9583\n","Epoch 14: val_acc did not improve from 0.96250\n","60/60 [==============================] - 11s 190ms/step - loss: 0.1323 - acc: 0.9583 - val_loss: 0.2109 - val_acc: 0.9312 - lr: 2.0000e-04\n","Epoch 15/40\n","60/60 [==============================] - ETA: 0s - loss: 0.1243 - acc: 0.9693\n","Epoch 15: val_acc did not improve from 0.96250\n","60/60 [==============================] - 11s 185ms/step - loss: 0.1243 - acc: 0.9693 - val_loss: 0.1749 - val_acc: 0.9479 - lr: 2.0000e-04\n","Epoch 16/40\n","60/60 [==============================] - ETA: 0s - loss: 0.1228 - acc: 0.9703\n","Epoch 16: val_acc did not improve from 0.96250\n","60/60 [==============================] - 11s 185ms/step - loss: 0.1228 - acc: 0.9703 - val_loss: 0.1745 - val_acc: 0.9458 - lr: 2.0000e-04\n","Epoch 17/40\n","60/60 [==============================] - ETA: 0s - loss: 0.1187 - acc: 0.9656\n","Epoch 17: val_acc did not improve from 0.96250\n","60/60 [==============================] - 11s 185ms/step - loss: 0.1187 - acc: 0.9656 - val_loss: 0.1750 - val_acc: 0.9458 - lr: 2.0000e-04\n","Epoch 18/40\n","60/60 [==============================] - ETA: 0s - loss: 0.1140 - acc: 0.9708\n","Epoch 18: val_acc did not improve from 0.96250\n","60/60 [==============================] - 11s 190ms/step - loss: 0.1140 - acc: 0.9708 - val_loss: 0.1735 - val_acc: 0.9417 - lr: 2.0000e-04\n","Epoch 19/40\n","60/60 [==============================] - ETA: 0s - loss: 0.1097 - acc: 0.9703\n","Epoch 19: val_acc did not improve from 0.96250\n","60/60 [==============================] - 11s 184ms/step - loss: 0.1097 - acc: 0.9703 - val_loss: 0.1666 - val_acc: 0.9521 - lr: 2.0000e-04\n","Epoch 20/40\n","60/60 [==============================] - ETA: 0s - loss: 0.1084 - acc: 0.9734\n","Epoch 20: val_acc did not improve from 0.96250\n","60/60 [==============================] - 11s 184ms/step - loss: 0.1084 - acc: 0.9734 - val_loss: 0.1776 - val_acc: 0.9479 - lr: 2.0000e-04\n","Epoch 21/40\n","60/60 [==============================] - ETA: 0s - loss: 0.1051 - acc: 0.9719\n","Epoch 21: val_acc did not improve from 0.96250\n","60/60 [==============================] - 11s 190ms/step - loss: 0.1051 - acc: 0.9719 - val_loss: 0.1693 - val_acc: 0.9417 - lr: 2.0000e-04\n","Epoch 22/40\n","60/60 [==============================] - ETA: 0s - loss: 0.1039 - acc: 0.9714\n","Epoch 22: val_acc did not improve from 0.96250\n","60/60 [==============================] - 11s 190ms/step - loss: 0.1039 - acc: 0.9714 - val_loss: 0.1609 - val_acc: 0.9563 - lr: 2.0000e-04\n","Epoch 23/40\n","60/60 [==============================] - ETA: 0s - loss: 0.1047 - acc: 0.9688\n","Epoch 23: val_acc did not improve from 0.96250\n","60/60 [==============================] - 11s 184ms/step - loss: 0.1047 - acc: 0.9688 - val_loss: 0.1626 - val_acc: 0.9438 - lr: 2.0000e-04\n","Epoch 24/40\n","60/60 [==============================] - ETA: 0s - loss: 0.1022 - acc: 0.9661\n","Epoch 24: val_acc did not improve from 0.96250\n","60/60 [==============================] - 11s 184ms/step - loss: 0.1022 - acc: 0.9661 - val_loss: 0.1663 - val_acc: 0.9458 - lr: 2.0000e-04\n","Epoch 25/40\n","60/60 [==============================] - ETA: 0s - loss: 0.0926 - acc: 0.9755\n","Epoch 25: val_acc did not improve from 0.96250\n","60/60 [==============================] - 11s 190ms/step - loss: 0.0926 - acc: 0.9755 - val_loss: 0.1567 - val_acc: 0.9521 - lr: 2.0000e-04\n","Epoch 26/40\n","60/60 [==============================] - ETA: 0s - loss: 0.0923 - acc: 0.9771\n","Epoch 26: val_acc did not improve from 0.96250\n","60/60 [==============================] - 11s 190ms/step - loss: 0.0923 - acc: 0.9771 - val_loss: 0.1597 - val_acc: 0.9479 - lr: 2.0000e-04\n","Epoch 27/40\n","60/60 [==============================] - ETA: 0s - loss: 0.0930 - acc: 0.9719\n","Epoch 27: val_acc did not improve from 0.96250\n","60/60 [==============================] - 11s 184ms/step - loss: 0.0930 - acc: 0.9719 - val_loss: 0.1643 - val_acc: 0.9479 - lr: 2.0000e-04\n","Epoch 28/40\n","60/60 [==============================] - ETA: 0s - loss: 0.0861 - acc: 0.9771\n","Epoch 28: val_acc did not improve from 0.96250\n","60/60 [==============================] - 11s 184ms/step - loss: 0.0861 - acc: 0.9771 - val_loss: 0.1537 - val_acc: 0.9479 - lr: 2.0000e-04\n","Epoch 29/40\n","60/60 [==============================] - ETA: 0s - loss: 0.0786 - acc: 0.9818\n","Epoch 29: val_acc did not improve from 0.96250\n","60/60 [==============================] - 11s 191ms/step - loss: 0.0786 - acc: 0.9818 - val_loss: 0.1493 - val_acc: 0.9563 - lr: 2.0000e-04\n","Epoch 30/40\n","60/60 [==============================] - ETA: 0s - loss: 0.0798 - acc: 0.9771\n","Epoch 30: val_acc did not improve from 0.96250\n","60/60 [==============================] - 11s 185ms/step - loss: 0.0798 - acc: 0.9771 - val_loss: 0.1850 - val_acc: 0.9354 - lr: 2.0000e-04\n","Epoch 31/40\n","60/60 [==============================] - ETA: 0s - loss: 0.0772 - acc: 0.9812\n","Epoch 31: val_acc did not improve from 0.96250\n","60/60 [==============================] - 11s 191ms/step - loss: 0.0772 - acc: 0.9812 - val_loss: 0.1443 - val_acc: 0.9583 - lr: 2.0000e-04\n","Epoch 32/40\n","60/60 [==============================] - ETA: 0s - loss: 0.0767 - acc: 0.9797\n","Epoch 32: val_acc did not improve from 0.96250\n","60/60 [==============================] - 11s 185ms/step - loss: 0.0767 - acc: 0.9797 - val_loss: 0.1441 - val_acc: 0.9563 - lr: 2.0000e-04\n","Epoch 33/40\n","60/60 [==============================] - ETA: 0s - loss: 0.0718 - acc: 0.9802\n","Epoch 33: val_acc did not improve from 0.96250\n","60/60 [==============================] - 11s 191ms/step - loss: 0.0718 - acc: 0.9802 - val_loss: 0.1621 - val_acc: 0.9458 - lr: 2.0000e-04\n","Epoch 34/40\n","60/60 [==============================] - ETA: 0s - loss: 0.0683 - acc: 0.9844\n","Epoch 34: val_acc did not improve from 0.96250\n","60/60 [==============================] - 11s 191ms/step - loss: 0.0683 - acc: 0.9844 - val_loss: 0.1447 - val_acc: 0.9542 - lr: 2.0000e-04\n","Epoch 35/40\n","60/60 [==============================] - ETA: 0s - loss: 0.0702 - acc: 0.9812\n","Epoch 35: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n","\n","Epoch 35: val_acc did not improve from 0.96250\n","60/60 [==============================] - 11s 185ms/step - loss: 0.0702 - acc: 0.9812 - val_loss: 0.1652 - val_acc: 0.9458 - lr: 2.0000e-04\n","Epoch 36/40\n","60/60 [==============================] - ETA: 0s - loss: 0.0663 - acc: 0.9839\n","Epoch 36: val_acc did not improve from 0.96250\n","60/60 [==============================] - 11s 191ms/step - loss: 0.0663 - acc: 0.9839 - val_loss: 0.1433 - val_acc: 0.9521 - lr: 4.0000e-05\n","Epoch 37/40\n","60/60 [==============================] - ETA: 0s - loss: 0.0588 - acc: 0.9891\n","Epoch 37: val_acc did not improve from 0.96250\n","60/60 [==============================] - 11s 191ms/step - loss: 0.0588 - acc: 0.9891 - val_loss: 0.1475 - val_acc: 0.9521 - lr: 4.0000e-05\n","Epoch 38/40\n","60/60 [==============================] - ETA: 0s - loss: 0.0608 - acc: 0.9854\n","Epoch 38: val_acc did not improve from 0.96250\n","60/60 [==============================] - 11s 185ms/step - loss: 0.0608 - acc: 0.9854 - val_loss: 0.1415 - val_acc: 0.9542 - lr: 4.0000e-05\n","Epoch 39/40\n","60/60 [==============================] - ETA: 0s - loss: 0.0598 - acc: 0.9875\n","Epoch 39: val_acc did not improve from 0.96250\n","60/60 [==============================] - 11s 191ms/step - loss: 0.0598 - acc: 0.9875 - val_loss: 0.1400 - val_acc: 0.9563 - lr: 4.0000e-05\n","Epoch 40/40\n","60/60 [==============================] - ETA: 0s - loss: 0.0593 - acc: 0.9880\n","Epoch 40: val_acc did not improve from 0.96250\n","60/60 [==============================] - 11s 190ms/step - loss: 0.0593 - acc: 0.9880 - val_loss: 0.1479 - val_acc: 0.9521 - lr: 4.0000e-05\n","Batch size: 64\n","\n","Epoch 1/40\n","30/30 [==============================] - ETA: 0s - loss: 1.1854 - acc: 0.5661\n","Epoch 1: val_acc did not improve from 0.96250\n","30/30 [==============================] - 17s 397ms/step - loss: 1.1854 - acc: 0.5661 - val_loss: 0.5988 - val_acc: 0.7479 - lr: 0.0010\n","Epoch 2/40\n","30/30 [==============================] - ETA: 0s - loss: 0.5731 - acc: 0.7161\n","Epoch 2: val_acc did not improve from 0.96250\n","30/30 [==============================] - 12s 389ms/step - loss: 0.5731 - acc: 0.7161 - val_loss: 0.5507 - val_acc: 0.6938 - lr: 0.0010\n","Epoch 3/40\n","30/30 [==============================] - ETA: 0s - loss: 0.5095 - acc: 0.7667\n","Epoch 3: val_acc did not improve from 0.96250\n","30/30 [==============================] - 11s 384ms/step - loss: 0.5095 - acc: 0.7667 - val_loss: 0.4650 - val_acc: 0.7979 - lr: 0.0010\n","Epoch 4/40\n","30/30 [==============================] - ETA: 0s - loss: 0.4384 - acc: 0.8396\n","Epoch 4: val_acc did not improve from 0.96250\n","30/30 [==============================] - 11s 371ms/step - loss: 0.4384 - acc: 0.8396 - val_loss: 0.4118 - val_acc: 0.8479 - lr: 0.0010\n","Epoch 5/40\n","30/30 [==============================] - ETA: 0s - loss: 0.3995 - acc: 0.8464\n","Epoch 5: val_acc did not improve from 0.96250\n","30/30 [==============================] - 11s 365ms/step - loss: 0.3995 - acc: 0.8464 - val_loss: 0.3735 - val_acc: 0.8667 - lr: 0.0010\n","Epoch 6/40\n","30/30 [==============================] - ETA: 0s - loss: 0.3704 - acc: 0.8516\n","Epoch 6: val_acc did not improve from 0.96250\n","30/30 [==============================] - 11s 363ms/step - loss: 0.3704 - acc: 0.8516 - val_loss: 0.3458 - val_acc: 0.8750 - lr: 0.0010\n","Epoch 7/40\n","30/30 [==============================] - ETA: 0s - loss: 0.3190 - acc: 0.8917\n","Epoch 7: val_acc did not improve from 0.96250\n","30/30 [==============================] - 11s 365ms/step - loss: 0.3190 - acc: 0.8917 - val_loss: 0.3239 - val_acc: 0.8792 - lr: 0.0010\n","Epoch 8/40\n","30/30 [==============================] - ETA: 0s - loss: 0.2972 - acc: 0.9005\n","Epoch 8: val_acc did not improve from 0.96250\n","30/30 [==============================] - 11s 369ms/step - loss: 0.2972 - acc: 0.9005 - val_loss: 0.3054 - val_acc: 0.8792 - lr: 0.0010\n","Epoch 9/40\n","30/30 [==============================] - ETA: 0s - loss: 0.2660 - acc: 0.9089\n","Epoch 9: val_acc did not improve from 0.96250\n","30/30 [==============================] - 11s 371ms/step - loss: 0.2660 - acc: 0.9089 - val_loss: 0.2901 - val_acc: 0.9042 - lr: 0.0010\n","Epoch 10/40\n","30/30 [==============================] - ETA: 0s - loss: 0.2484 - acc: 0.9156\n","Epoch 10: val_acc did not improve from 0.96250\n","30/30 [==============================] - 11s 372ms/step - loss: 0.2484 - acc: 0.9156 - val_loss: 0.2851 - val_acc: 0.9042 - lr: 0.0010\n","Epoch 11/40\n","30/30 [==============================] - ETA: 0s - loss: 0.2301 - acc: 0.9234\n","Epoch 11: val_acc did not improve from 0.96250\n","30/30 [==============================] - 11s 371ms/step - loss: 0.2301 - acc: 0.9234 - val_loss: 0.2468 - val_acc: 0.9229 - lr: 0.0010\n","Epoch 12/40\n","30/30 [==============================] - ETA: 0s - loss: 0.2133 - acc: 0.9297\n","Epoch 12: val_acc did not improve from 0.96250\n","30/30 [==============================] - 11s 371ms/step - loss: 0.2133 - acc: 0.9297 - val_loss: 0.2402 - val_acc: 0.9146 - lr: 0.0010\n","Epoch 13/40\n","30/30 [==============================] - ETA: 0s - loss: 0.1931 - acc: 0.9375\n","Epoch 13: val_acc did not improve from 0.96250\n","30/30 [==============================] - 11s 369ms/step - loss: 0.1931 - acc: 0.9375 - val_loss: 0.2199 - val_acc: 0.9250 - lr: 0.0010\n","Epoch 14/40\n","30/30 [==============================] - ETA: 0s - loss: 0.1826 - acc: 0.9370\n","Epoch 14: val_acc did not improve from 0.96250\n","30/30 [==============================] - 11s 368ms/step - loss: 0.1826 - acc: 0.9370 - val_loss: 0.2123 - val_acc: 0.9354 - lr: 0.0010\n","Epoch 15/40\n","30/30 [==============================] - ETA: 0s - loss: 0.1632 - acc: 0.9516\n","Epoch 15: val_acc did not improve from 0.96250\n","30/30 [==============================] - 11s 368ms/step - loss: 0.1632 - acc: 0.9516 - val_loss: 0.2014 - val_acc: 0.9312 - lr: 0.0010\n","Epoch 16/40\n","30/30 [==============================] - ETA: 0s - loss: 0.1618 - acc: 0.9490\n","Epoch 16: val_acc did not improve from 0.96250\n","30/30 [==============================] - 11s 368ms/step - loss: 0.1618 - acc: 0.9490 - val_loss: 0.1959 - val_acc: 0.9312 - lr: 0.0010\n","Epoch 17/40\n","30/30 [==============================] - ETA: 0s - loss: 0.1791 - acc: 0.9370\n","Epoch 17: val_acc did not improve from 0.96250\n","30/30 [==============================] - 11s 368ms/step - loss: 0.1791 - acc: 0.9370 - val_loss: 0.1886 - val_acc: 0.9354 - lr: 0.0010\n","Epoch 18/40\n","30/30 [==============================] - ETA: 0s - loss: 0.1799 - acc: 0.9302\n","Epoch 18: val_acc did not improve from 0.96250\n","30/30 [==============================] - 11s 368ms/step - loss: 0.1799 - acc: 0.9302 - val_loss: 0.1828 - val_acc: 0.9396 - lr: 0.0010\n","Epoch 19/40\n","30/30 [==============================] - ETA: 0s - loss: 0.1413 - acc: 0.9536\n","Epoch 19: val_acc did not improve from 0.96250\n","30/30 [==============================] - 11s 369ms/step - loss: 0.1413 - acc: 0.9536 - val_loss: 0.1760 - val_acc: 0.9417 - lr: 0.0010\n","Epoch 20/40\n","30/30 [==============================] - ETA: 0s - loss: 0.1367 - acc: 0.9536\n","Epoch 20: val_acc did not improve from 0.96250\n","30/30 [==============================] - 11s 368ms/step - loss: 0.1367 - acc: 0.9536 - val_loss: 0.3823 - val_acc: 0.8229 - lr: 0.0010\n","Epoch 21/40\n","30/30 [==============================] - ETA: 0s - loss: 0.1338 - acc: 0.9531\n","Epoch 21: val_acc did not improve from 0.96250\n","30/30 [==============================] - 11s 369ms/step - loss: 0.1338 - acc: 0.9531 - val_loss: 0.2193 - val_acc: 0.9146 - lr: 0.0010\n","Epoch 22/40\n","30/30 [==============================] - ETA: 0s - loss: 0.1131 - acc: 0.9630\n","Epoch 22: val_acc did not improve from 0.96250\n","30/30 [==============================] - 11s 369ms/step - loss: 0.1131 - acc: 0.9630 - val_loss: 0.1758 - val_acc: 0.9479 - lr: 0.0010\n","Epoch 23/40\n","30/30 [==============================] - ETA: 0s - loss: 0.1137 - acc: 0.9615\n","Epoch 23: val_acc did not improve from 0.96250\n","30/30 [==============================] - 11s 370ms/step - loss: 0.1137 - acc: 0.9615 - val_loss: 0.1672 - val_acc: 0.9500 - lr: 0.0010\n","Epoch 24/40\n","30/30 [==============================] - ETA: 0s - loss: 0.0962 - acc: 0.9750\n","Epoch 24: val_acc did not improve from 0.96250\n","30/30 [==============================] - 11s 369ms/step - loss: 0.0962 - acc: 0.9750 - val_loss: 0.1565 - val_acc: 0.9563 - lr: 0.0010\n","Epoch 25/40\n","30/30 [==============================] - ETA: 0s - loss: 0.0929 - acc: 0.9729\n","Epoch 25: val_acc did not improve from 0.96250\n","30/30 [==============================] - 11s 370ms/step - loss: 0.0929 - acc: 0.9729 - val_loss: 0.1636 - val_acc: 0.9500 - lr: 0.0010\n","Epoch 26/40\n","30/30 [==============================] - ETA: 0s - loss: 0.1001 - acc: 0.9714\n","Epoch 26: val_acc did not improve from 0.96250\n","30/30 [==============================] - 11s 370ms/step - loss: 0.1001 - acc: 0.9714 - val_loss: 0.1587 - val_acc: 0.9438 - lr: 0.0010\n","Epoch 27/40\n","30/30 [==============================] - ETA: 0s - loss: 0.1105 - acc: 0.9615\n","Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n","\n","Epoch 27: val_acc did not improve from 0.96250\n","30/30 [==============================] - 11s 371ms/step - loss: 0.1105 - acc: 0.9615 - val_loss: 0.1686 - val_acc: 0.9458 - lr: 0.0010\n","Epoch 28/40\n","30/30 [==============================] - ETA: 0s - loss: 0.0782 - acc: 0.9792\n","Epoch 28: val_acc did not improve from 0.96250\n","30/30 [==============================] - 11s 370ms/step - loss: 0.0782 - acc: 0.9792 - val_loss: 0.1491 - val_acc: 0.9563 - lr: 2.0000e-04\n","Epoch 29/40\n","30/30 [==============================] - ETA: 0s - loss: 0.0758 - acc: 0.9812\n","Epoch 29: val_acc did not improve from 0.96250\n","30/30 [==============================] - 11s 370ms/step - loss: 0.0758 - acc: 0.9812 - val_loss: 0.1502 - val_acc: 0.9542 - lr: 2.0000e-04\n","Epoch 30/40\n","30/30 [==============================] - ETA: 0s - loss: 0.0765 - acc: 0.9802\n","Epoch 30: val_acc did not improve from 0.96250\n","30/30 [==============================] - 11s 370ms/step - loss: 0.0765 - acc: 0.9802 - val_loss: 0.1584 - val_acc: 0.9479 - lr: 2.0000e-04\n","Epoch 31/40\n","30/30 [==============================] - ETA: 0s - loss: 0.0779 - acc: 0.9792\n","Epoch 31: val_acc did not improve from 0.96250\n","30/30 [==============================] - 11s 373ms/step - loss: 0.0779 - acc: 0.9792 - val_loss: 0.1460 - val_acc: 0.9625 - lr: 2.0000e-04\n","Epoch 32/40\n","30/30 [==============================] - ETA: 0s - loss: 0.0739 - acc: 0.9792\n","Epoch 32: val_acc did not improve from 0.96250\n","30/30 [==============================] - 11s 370ms/step - loss: 0.0739 - acc: 0.9792 - val_loss: 0.1582 - val_acc: 0.9479 - lr: 2.0000e-04\n","Epoch 33/40\n","30/30 [==============================] - ETA: 0s - loss: 0.0721 - acc: 0.9818\n","Epoch 33: val_acc did not improve from 0.96250\n","30/30 [==============================] - 11s 371ms/step - loss: 0.0721 - acc: 0.9818 - val_loss: 0.1552 - val_acc: 0.9479 - lr: 2.0000e-04\n","Epoch 34/40\n","30/30 [==============================] - ETA: 0s - loss: 0.0704 - acc: 0.9818\n","Epoch 34: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n","\n","Epoch 34: val_acc did not improve from 0.96250\n","30/30 [==============================] - 11s 370ms/step - loss: 0.0704 - acc: 0.9818 - val_loss: 0.1520 - val_acc: 0.9521 - lr: 2.0000e-04\n","Epoch 35/40\n","30/30 [==============================] - ETA: 0s - loss: 0.0706 - acc: 0.9828\n","Epoch 35: val_acc did not improve from 0.96250\n","30/30 [==============================] - 11s 371ms/step - loss: 0.0706 - acc: 0.9828 - val_loss: 0.1518 - val_acc: 0.9521 - lr: 4.0000e-05\n","Epoch 36/40\n","30/30 [==============================] - ETA: 0s - loss: 0.0664 - acc: 0.9839\n","Epoch 36: val_acc did not improve from 0.96250\n","30/30 [==============================] - 11s 370ms/step - loss: 0.0664 - acc: 0.9839 - val_loss: 0.1522 - val_acc: 0.9500 - lr: 4.0000e-05\n","Epoch 37/40\n","30/30 [==============================] - ETA: 0s - loss: 0.0690 - acc: 0.9839\n","Epoch 37: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n","\n","Epoch 37: val_acc did not improve from 0.96250\n","30/30 [==============================] - 11s 371ms/step - loss: 0.0690 - acc: 0.9839 - val_loss: 0.1469 - val_acc: 0.9542 - lr: 4.0000e-05\n","Epoch 38/40\n","30/30 [==============================] - ETA: 0s - loss: 0.0704 - acc: 0.9833\n","Epoch 38: val_acc did not improve from 0.96250\n","30/30 [==============================] - 11s 370ms/step - loss: 0.0704 - acc: 0.9833 - val_loss: 0.1489 - val_acc: 0.9521 - lr: 8.0000e-06\n","Epoch 39/40\n","30/30 [==============================] - ETA: 0s - loss: 0.0687 - acc: 0.9839\n","Epoch 39: val_acc did not improve from 0.96250\n","30/30 [==============================] - 11s 371ms/step - loss: 0.0687 - acc: 0.9839 - val_loss: 0.1485 - val_acc: 0.9521 - lr: 8.0000e-06\n","Epoch 40/40\n","30/30 [==============================] - ETA: 0s - loss: 0.0674 - acc: 0.9854\n","Epoch 40: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n","\n","Epoch 40: val_acc did not improve from 0.96250\n","30/30 [==============================] - 11s 370ms/step - loss: 0.0674 - acc: 0.9854 - val_loss: 0.1491 - val_acc: 0.9521 - lr: 8.0000e-06\n"]}],"source":["## radi se grid search na veličinu batcha\n","for bs in [16, 32, 64]:\n","  print('Batch size: {0}\\n'.format(bs))\n","\n","  model_vgg16 = VGG16(\n","  input_shape=(200, 200, 3),\n","  include_top=False,\n","  weights='imagenet'\n","  )\n","\n","  for layer in model_vgg16.layers:\n","      layer.trainable = False\n","\n","  x = layers.Flatten()(model_vgg16.output)\n","\n","  ## koristimo dropout za sprečavanje prenaučenosti i bolju generalizaciju\n","  x = layers.Dropout(0.25)(x)\n","\n","  x = layers.Dense(units=256, activation=\"relu\")(x)\n","  x = layers.Dense(units=1, activation=\"sigmoid\")(x)\n","  model = tf.keras.Model(model_vgg16.input, x)\n","\n","  model.compile(\n","      optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3),\n","      loss=tf.keras.losses.BinaryCrossentropy(),\n","      metrics = ['acc']\n","  )\n","\n","  vgg = model.fit(x=train_x, y=y_train, \n","                  validation_data=(validation_x, y_validation),\n","                  batch_size=bs,\n","                  epochs=40, \n","                  verbose=1, \n","                  callbacks=[reduce_lr, checkpoint_callback])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1009340,"status":"ok","timestamp":1672335275892,"user":{"displayName":"Tihomir Pavic","userId":"12556438120461886781"},"user_tz":-60},"id":"AT44xdMW4bFH","outputId":"b1339346-a437-4fa3-e8f8-adcce8a53f9b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of neurons: 128\n","\n","Epoch 1/40\n","120/120 [==============================] - ETA: 0s - loss: 0.6827 - acc: 0.6427\n","Epoch 1: val_acc improved from -inf to 0.79375, saving model to /content/gdrive/MyDrive/asub_dataset/colab - biljeznice/vgg16-model/best_model\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r120/120 [==============================] - 16s 126ms/step - loss: 0.6827 - acc: 0.6427 - val_loss: 0.4680 - val_acc: 0.7937 - lr: 0.0010\n","Epoch 2/40\n","120/120 [==============================] - ETA: 0s - loss: 0.4218 - acc: 0.8219\n","Epoch 2: val_acc improved from 0.79375 to 0.87292, saving model to /content/gdrive/MyDrive/asub_dataset/colab - biljeznice/vgg16-model/best_model\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r120/120 [==============================] - 14s 114ms/step - loss: 0.4218 - acc: 0.8219 - val_loss: 0.3470 - val_acc: 0.8729 - lr: 0.0010\n","Epoch 3/40\n","120/120 [==============================] - ETA: 0s - loss: 0.3315 - acc: 0.8708\n","Epoch 3: val_acc improved from 0.87292 to 0.90208, saving model to /content/gdrive/MyDrive/asub_dataset/colab - biljeznice/vgg16-model/best_model\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r120/120 [==============================] - 14s 115ms/step - loss: 0.3315 - acc: 0.8708 - val_loss: 0.3044 - val_acc: 0.9021 - lr: 0.0010\n","Epoch 4/40\n","120/120 [==============================] - ETA: 0s - loss: 0.2734 - acc: 0.8990\n","Epoch 4: val_acc improved from 0.90208 to 0.91458, saving model to /content/gdrive/MyDrive/asub_dataset/colab - biljeznice/vgg16-model/best_model\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r120/120 [==============================] - 14s 118ms/step - loss: 0.2734 - acc: 0.8990 - val_loss: 0.2499 - val_acc: 0.9146 - lr: 0.0010\n","Epoch 5/40\n","120/120 [==============================] - ETA: 0s - loss: 0.2400 - acc: 0.9099\n","Epoch 5: val_acc did not improve from 0.91458\n","120/120 [==============================] - 12s 96ms/step - loss: 0.2400 - acc: 0.9099 - val_loss: 0.2307 - val_acc: 0.9146 - lr: 0.0010\n","Epoch 6/40\n","120/120 [==============================] - ETA: 0s - loss: 0.2401 - acc: 0.8974\n","Epoch 6: val_acc improved from 0.91458 to 0.93125, saving model to /content/gdrive/MyDrive/asub_dataset/colab - biljeznice/vgg16-model/best_model\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r120/120 [==============================] - 14s 117ms/step - loss: 0.2401 - acc: 0.8974 - val_loss: 0.1973 - val_acc: 0.9312 - lr: 0.0010\n","Epoch 7/40\n","120/120 [==============================] - ETA: 0s - loss: 0.1910 - acc: 0.9297\n","Epoch 7: val_acc improved from 0.93125 to 0.93958, saving model to /content/gdrive/MyDrive/asub_dataset/colab - biljeznice/vgg16-model/best_model\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r120/120 [==============================] - 14s 116ms/step - loss: 0.1910 - acc: 0.9297 - val_loss: 0.1859 - val_acc: 0.9396 - lr: 0.0010\n","Epoch 8/40\n","120/120 [==============================] - ETA: 0s - loss: 0.1668 - acc: 0.9370\n","Epoch 8: val_acc did not improve from 0.93958\n","120/120 [==============================] - 12s 98ms/step - loss: 0.1668 - acc: 0.9370 - val_loss: 0.2728 - val_acc: 0.8833 - lr: 0.0010\n","Epoch 9/40\n","120/120 [==============================] - ETA: 0s - loss: 0.1522 - acc: 0.9432\n","Epoch 9: val_acc did not improve from 0.93958\n","120/120 [==============================] - 11s 95ms/step - loss: 0.1522 - acc: 0.9432 - val_loss: 0.2575 - val_acc: 0.8875 - lr: 0.0010\n","Epoch 10/40\n","120/120 [==============================] - ETA: 0s - loss: 0.1420 - acc: 0.9427\n","Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n","\n","Epoch 10: val_acc did not improve from 0.93958\n","120/120 [==============================] - 11s 95ms/step - loss: 0.1420 - acc: 0.9427 - val_loss: 0.2322 - val_acc: 0.9167 - lr: 0.0010\n","Epoch 11/40\n","120/120 [==============================] - ETA: 0s - loss: 0.1077 - acc: 0.9677\n","Epoch 11: val_acc improved from 0.93958 to 0.95625, saving model to /content/gdrive/MyDrive/asub_dataset/colab - biljeznice/vgg16-model/best_model\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r120/120 [==============================] - 14s 116ms/step - loss: 0.1077 - acc: 0.9677 - val_loss: 0.1520 - val_acc: 0.9563 - lr: 2.0000e-04\n","Epoch 12/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0970 - acc: 0.9719\n","Epoch 12: val_acc did not improve from 0.95625\n","120/120 [==============================] - 11s 95ms/step - loss: 0.0970 - acc: 0.9719 - val_loss: 0.1813 - val_acc: 0.9229 - lr: 2.0000e-04\n","Epoch 13/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0947 - acc: 0.9708\n","Epoch 13: val_acc did not improve from 0.95625\n","120/120 [==============================] - 12s 98ms/step - loss: 0.0947 - acc: 0.9708 - val_loss: 0.1483 - val_acc: 0.9521 - lr: 2.0000e-04\n","Epoch 14/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0925 - acc: 0.9719\n","Epoch 14: val_acc did not improve from 0.95625\n","120/120 [==============================] - 12s 98ms/step - loss: 0.0925 - acc: 0.9719 - val_loss: 0.1741 - val_acc: 0.9333 - lr: 2.0000e-04\n","Epoch 15/40\n","120/120 [==============================] - ETA: 0s - loss: 0.1081 - acc: 0.9620\n","Epoch 15: val_acc improved from 0.95625 to 0.96042, saving model to /content/gdrive/MyDrive/asub_dataset/colab - biljeznice/vgg16-model/best_model\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r120/120 [==============================] - 14s 115ms/step - loss: 0.1081 - acc: 0.9620 - val_loss: 0.1434 - val_acc: 0.9604 - lr: 2.0000e-04\n","Epoch 16/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0817 - acc: 0.9729\n","Epoch 16: val_acc did not improve from 0.96042\n","120/120 [==============================] - 12s 98ms/step - loss: 0.0817 - acc: 0.9729 - val_loss: 0.1568 - val_acc: 0.9458 - lr: 2.0000e-04\n","Epoch 17/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0809 - acc: 0.9755\n","Epoch 17: val_acc did not improve from 0.96042\n","120/120 [==============================] - 11s 95ms/step - loss: 0.0809 - acc: 0.9755 - val_loss: 0.1412 - val_acc: 0.9604 - lr: 2.0000e-04\n","Epoch 18/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0779 - acc: 0.9745\n","Epoch 18: val_acc did not improve from 0.96042\n","120/120 [==============================] - 11s 95ms/step - loss: 0.0779 - acc: 0.9745 - val_loss: 0.1598 - val_acc: 0.9438 - lr: 2.0000e-04\n","Epoch 19/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0778 - acc: 0.9740\n","Epoch 19: val_acc did not improve from 0.96042\n","120/120 [==============================] - 12s 97ms/step - loss: 0.0778 - acc: 0.9740 - val_loss: 0.1425 - val_acc: 0.9563 - lr: 2.0000e-04\n","Epoch 20/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0771 - acc: 0.9755\n","Epoch 20: val_acc did not improve from 0.96042\n","120/120 [==============================] - 11s 95ms/step - loss: 0.0771 - acc: 0.9755 - val_loss: 0.1383 - val_acc: 0.9604 - lr: 2.0000e-04\n","Epoch 21/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0753 - acc: 0.9729\n","Epoch 21: val_acc did not improve from 0.96042\n","120/120 [==============================] - 11s 95ms/step - loss: 0.0753 - acc: 0.9729 - val_loss: 0.1582 - val_acc: 0.9396 - lr: 2.0000e-04\n","Epoch 22/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0687 - acc: 0.9802\n","Epoch 22: val_acc improved from 0.96042 to 0.96667, saving model to /content/gdrive/MyDrive/asub_dataset/colab - biljeznice/vgg16-model/best_model\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r120/120 [==============================] - 14s 117ms/step - loss: 0.0687 - acc: 0.9802 - val_loss: 0.1341 - val_acc: 0.9667 - lr: 2.0000e-04\n","Epoch 23/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0818 - acc: 0.9693\n","Epoch 23: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 97ms/step - loss: 0.0818 - acc: 0.9693 - val_loss: 0.1359 - val_acc: 0.9625 - lr: 2.0000e-04\n","Epoch 24/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0703 - acc: 0.9786\n","Epoch 24: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 98ms/step - loss: 0.0703 - acc: 0.9786 - val_loss: 0.1531 - val_acc: 0.9458 - lr: 2.0000e-04\n","Epoch 25/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0808 - acc: 0.9771\n","Epoch 25: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n","\n","Epoch 25: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 98ms/step - loss: 0.0808 - acc: 0.9771 - val_loss: 0.1549 - val_acc: 0.9417 - lr: 2.0000e-04\n","Epoch 26/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0541 - acc: 0.9854\n","Epoch 26: val_acc did not improve from 0.96667\n","120/120 [==============================] - 11s 96ms/step - loss: 0.0541 - acc: 0.9854 - val_loss: 0.1446 - val_acc: 0.9521 - lr: 4.0000e-05\n","Epoch 27/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0576 - acc: 0.9823\n","Epoch 27: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 98ms/step - loss: 0.0576 - acc: 0.9823 - val_loss: 0.1361 - val_acc: 0.9604 - lr: 4.0000e-05\n","Epoch 28/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0605 - acc: 0.9812\n","Epoch 28: val_acc did not improve from 0.96667\n","120/120 [==============================] - 11s 95ms/step - loss: 0.0605 - acc: 0.9812 - val_loss: 0.1321 - val_acc: 0.9604 - lr: 4.0000e-05\n","Epoch 29/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0606 - acc: 0.9828\n","Epoch 29: val_acc did not improve from 0.96667\n","120/120 [==============================] - 11s 95ms/step - loss: 0.0606 - acc: 0.9828 - val_loss: 0.1358 - val_acc: 0.9625 - lr: 4.0000e-05\n","Epoch 30/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0558 - acc: 0.9859\n","Epoch 30: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 98ms/step - loss: 0.0558 - acc: 0.9859 - val_loss: 0.1384 - val_acc: 0.9563 - lr: 4.0000e-05\n","Epoch 31/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0545 - acc: 0.9859\n","Epoch 31: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n","\n","Epoch 31: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 98ms/step - loss: 0.0545 - acc: 0.9859 - val_loss: 0.1383 - val_acc: 0.9563 - lr: 4.0000e-05\n","Epoch 32/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0580 - acc: 0.9823\n","Epoch 32: val_acc did not improve from 0.96667\n","120/120 [==============================] - 11s 95ms/step - loss: 0.0580 - acc: 0.9823 - val_loss: 0.1344 - val_acc: 0.9625 - lr: 8.0000e-06\n","Epoch 33/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0541 - acc: 0.9849\n","Epoch 33: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 97ms/step - loss: 0.0541 - acc: 0.9849 - val_loss: 0.1343 - val_acc: 0.9625 - lr: 8.0000e-06\n","Epoch 34/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0578 - acc: 0.9833\n","Epoch 34: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n","\n","Epoch 34: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 99ms/step - loss: 0.0578 - acc: 0.9833 - val_loss: 0.1336 - val_acc: 0.9625 - lr: 8.0000e-06\n","Epoch 35/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0513 - acc: 0.9880\n","Epoch 35: val_acc did not improve from 0.96667\n","120/120 [==============================] - 11s 95ms/step - loss: 0.0513 - acc: 0.9880 - val_loss: 0.1357 - val_acc: 0.9583 - lr: 1.6000e-06\n","Epoch 36/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0612 - acc: 0.9792\n","Epoch 36: val_acc did not improve from 0.96667\n","120/120 [==============================] - 11s 95ms/step - loss: 0.0612 - acc: 0.9792 - val_loss: 0.1359 - val_acc: 0.9583 - lr: 1.6000e-06\n","Epoch 37/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0578 - acc: 0.9833\n","Epoch 37: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n","\n","Epoch 37: val_acc did not improve from 0.96667\n","120/120 [==============================] - 11s 95ms/step - loss: 0.0578 - acc: 0.9833 - val_loss: 0.1370 - val_acc: 0.9563 - lr: 1.6000e-06\n","Epoch 38/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0572 - acc: 0.9818\n","Epoch 38: val_acc did not improve from 0.96667\n","120/120 [==============================] - 11s 95ms/step - loss: 0.0572 - acc: 0.9818 - val_loss: 0.1370 - val_acc: 0.9563 - lr: 3.2000e-07\n","Epoch 39/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0548 - acc: 0.9844\n","Epoch 39: val_acc did not improve from 0.96667\n","120/120 [==============================] - 11s 95ms/step - loss: 0.0548 - acc: 0.9844 - val_loss: 0.1372 - val_acc: 0.9563 - lr: 3.2000e-07\n","Epoch 40/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0574 - acc: 0.9859\n","Epoch 40: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n","\n","Epoch 40: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 98ms/step - loss: 0.0574 - acc: 0.9859 - val_loss: 0.1373 - val_acc: 0.9563 - lr: 3.2000e-07\n","Number of neurons: 512\n","\n","Epoch 1/40\n","120/120 [==============================] - ETA: 0s - loss: 0.7810 - acc: 0.7068\n","Epoch 1: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 98ms/step - loss: 0.7810 - acc: 0.7068 - val_loss: 0.3839 - val_acc: 0.8583 - lr: 0.0010\n","Epoch 2/40\n","120/120 [==============================] - ETA: 0s - loss: 0.4006 - acc: 0.8120\n","Epoch 2: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 102ms/step - loss: 0.4006 - acc: 0.8120 - val_loss: 0.4268 - val_acc: 0.7792 - lr: 0.0010\n","Epoch 3/40\n","120/120 [==============================] - ETA: 0s - loss: 0.3266 - acc: 0.8651\n","Epoch 3: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 102ms/step - loss: 0.3266 - acc: 0.8651 - val_loss: 0.3331 - val_acc: 0.8438 - lr: 0.0010\n","Epoch 4/40\n","120/120 [==============================] - ETA: 0s - loss: 0.2744 - acc: 0.8870\n","Epoch 4: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 99ms/step - loss: 0.2744 - acc: 0.8870 - val_loss: 0.2295 - val_acc: 0.9125 - lr: 0.0010\n","Epoch 5/40\n","120/120 [==============================] - ETA: 0s - loss: 0.2365 - acc: 0.9073\n","Epoch 5: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 99ms/step - loss: 0.2365 - acc: 0.9073 - val_loss: 0.2139 - val_acc: 0.9312 - lr: 0.0010\n","Epoch 6/40\n","120/120 [==============================] - ETA: 0s - loss: 0.2036 - acc: 0.9198\n","Epoch 6: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 98ms/step - loss: 0.2036 - acc: 0.9198 - val_loss: 0.1926 - val_acc: 0.9271 - lr: 0.0010\n","Epoch 7/40\n","120/120 [==============================] - ETA: 0s - loss: 0.1768 - acc: 0.9307\n","Epoch 7: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 97ms/step - loss: 0.1768 - acc: 0.9307 - val_loss: 0.4057 - val_acc: 0.8208 - lr: 0.0010\n","Epoch 8/40\n","120/120 [==============================] - ETA: 0s - loss: 0.2035 - acc: 0.9146\n","Epoch 8: val_acc did not improve from 0.96667\n","120/120 [==============================] - 11s 96ms/step - loss: 0.2035 - acc: 0.9146 - val_loss: 0.1708 - val_acc: 0.9417 - lr: 0.0010\n","Epoch 9/40\n","120/120 [==============================] - ETA: 0s - loss: 0.1361 - acc: 0.9526\n","Epoch 9: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 97ms/step - loss: 0.1361 - acc: 0.9526 - val_loss: 0.3293 - val_acc: 0.8562 - lr: 0.0010\n","Epoch 10/40\n","120/120 [==============================] - ETA: 0s - loss: 0.1553 - acc: 0.9370\n","Epoch 10: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 100ms/step - loss: 0.1553 - acc: 0.9370 - val_loss: 0.4939 - val_acc: 0.7854 - lr: 0.0010\n","Epoch 11/40\n","120/120 [==============================] - ETA: 0s - loss: 0.1796 - acc: 0.9312\n","Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n","\n","Epoch 11: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 100ms/step - loss: 0.1796 - acc: 0.9312 - val_loss: 0.1826 - val_acc: 0.9417 - lr: 0.0010\n","Epoch 12/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0892 - acc: 0.9677\n","Epoch 12: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 100ms/step - loss: 0.0892 - acc: 0.9677 - val_loss: 0.1546 - val_acc: 0.9521 - lr: 2.0000e-04\n","Epoch 13/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0756 - acc: 0.9755\n","Epoch 13: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 99ms/step - loss: 0.0756 - acc: 0.9755 - val_loss: 0.1503 - val_acc: 0.9500 - lr: 2.0000e-04\n","Epoch 14/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0802 - acc: 0.9724\n","Epoch 14: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 96ms/step - loss: 0.0802 - acc: 0.9724 - val_loss: 0.1556 - val_acc: 0.9438 - lr: 2.0000e-04\n","Epoch 15/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0690 - acc: 0.9802\n","Epoch 15: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 99ms/step - loss: 0.0690 - acc: 0.9802 - val_loss: 0.1505 - val_acc: 0.9500 - lr: 2.0000e-04\n","Epoch 16/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0815 - acc: 0.9688\n","Epoch 16: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n","\n","Epoch 16: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 99ms/step - loss: 0.0815 - acc: 0.9688 - val_loss: 0.1682 - val_acc: 0.9500 - lr: 2.0000e-04\n","Epoch 17/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0678 - acc: 0.9776\n","Epoch 17: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 97ms/step - loss: 0.0678 - acc: 0.9776 - val_loss: 0.1522 - val_acc: 0.9542 - lr: 4.0000e-05\n","Epoch 18/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0633 - acc: 0.9833\n","Epoch 18: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 99ms/step - loss: 0.0633 - acc: 0.9833 - val_loss: 0.1525 - val_acc: 0.9521 - lr: 4.0000e-05\n","Epoch 19/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0670 - acc: 0.9812\n","Epoch 19: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n","\n","Epoch 19: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 97ms/step - loss: 0.0670 - acc: 0.9812 - val_loss: 0.1592 - val_acc: 0.9479 - lr: 4.0000e-05\n","Epoch 20/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0662 - acc: 0.9792\n","Epoch 20: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 99ms/step - loss: 0.0662 - acc: 0.9792 - val_loss: 0.1474 - val_acc: 0.9583 - lr: 8.0000e-06\n","Epoch 21/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0696 - acc: 0.9792\n","Epoch 21: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 100ms/step - loss: 0.0696 - acc: 0.9792 - val_loss: 0.1511 - val_acc: 0.9521 - lr: 8.0000e-06\n","Epoch 22/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0624 - acc: 0.9818\n","Epoch 22: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 97ms/step - loss: 0.0624 - acc: 0.9818 - val_loss: 0.1513 - val_acc: 0.9521 - lr: 8.0000e-06\n","Epoch 23/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0650 - acc: 0.9818\n","Epoch 23: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n","\n","Epoch 23: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 97ms/step - loss: 0.0650 - acc: 0.9818 - val_loss: 0.1483 - val_acc: 0.9563 - lr: 8.0000e-06\n","Epoch 24/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0636 - acc: 0.9802\n","Epoch 24: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 99ms/step - loss: 0.0636 - acc: 0.9802 - val_loss: 0.1485 - val_acc: 0.9542 - lr: 1.6000e-06\n","Epoch 25/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0617 - acc: 0.9807\n","Epoch 25: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 99ms/step - loss: 0.0617 - acc: 0.9807 - val_loss: 0.1493 - val_acc: 0.9521 - lr: 1.6000e-06\n","Epoch 26/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0604 - acc: 0.9839\n","Epoch 26: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n","\n","Epoch 26: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 99ms/step - loss: 0.0604 - acc: 0.9839 - val_loss: 0.1485 - val_acc: 0.9542 - lr: 1.6000e-06\n","Epoch 27/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0655 - acc: 0.9797\n","Epoch 27: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 99ms/step - loss: 0.0655 - acc: 0.9797 - val_loss: 0.1491 - val_acc: 0.9542 - lr: 3.2000e-07\n","Epoch 28/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0617 - acc: 0.9828\n","Epoch 28: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 99ms/step - loss: 0.0617 - acc: 0.9828 - val_loss: 0.1496 - val_acc: 0.9521 - lr: 3.2000e-07\n","Epoch 29/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0607 - acc: 0.9823\n","Epoch 29: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n","\n","Epoch 29: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 99ms/step - loss: 0.0607 - acc: 0.9823 - val_loss: 0.1495 - val_acc: 0.9521 - lr: 3.2000e-07\n","Epoch 30/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0617 - acc: 0.9781\n","Epoch 30: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 99ms/step - loss: 0.0617 - acc: 0.9781 - val_loss: 0.1495 - val_acc: 0.9521 - lr: 6.4000e-08\n","Epoch 31/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0601 - acc: 0.9849\n","Epoch 31: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 99ms/step - loss: 0.0601 - acc: 0.9849 - val_loss: 0.1494 - val_acc: 0.9521 - lr: 6.4000e-08\n","Epoch 32/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0596 - acc: 0.9833\n","Epoch 32: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.\n","\n","Epoch 32: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 99ms/step - loss: 0.0596 - acc: 0.9833 - val_loss: 0.1494 - val_acc: 0.9521 - lr: 6.4000e-08\n","Epoch 33/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0616 - acc: 0.9802\n","Epoch 33: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 97ms/step - loss: 0.0616 - acc: 0.9802 - val_loss: 0.1494 - val_acc: 0.9521 - lr: 1.2800e-08\n","Epoch 34/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0634 - acc: 0.9781\n","Epoch 34: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 99ms/step - loss: 0.0634 - acc: 0.9781 - val_loss: 0.1494 - val_acc: 0.9521 - lr: 1.2800e-08\n","Epoch 35/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0626 - acc: 0.9797\n","Epoch 35: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.\n","\n","Epoch 35: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 96ms/step - loss: 0.0626 - acc: 0.9797 - val_loss: 0.1494 - val_acc: 0.9521 - lr: 1.2800e-08\n","Epoch 36/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0565 - acc: 0.9844\n","Epoch 36: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 97ms/step - loss: 0.0565 - acc: 0.9844 - val_loss: 0.1494 - val_acc: 0.9521 - lr: 2.5600e-09\n","Epoch 37/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0561 - acc: 0.9865\n","Epoch 37: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 97ms/step - loss: 0.0561 - acc: 0.9865 - val_loss: 0.1494 - val_acc: 0.9521 - lr: 2.5600e-09\n","Epoch 38/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0640 - acc: 0.9807\n","Epoch 38: ReduceLROnPlateau reducing learning rate to 1e-09.\n","\n","Epoch 38: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 99ms/step - loss: 0.0640 - acc: 0.9807 - val_loss: 0.1494 - val_acc: 0.9521 - lr: 2.5600e-09\n","Epoch 39/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0592 - acc: 0.9854\n","Epoch 39: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 99ms/step - loss: 0.0592 - acc: 0.9854 - val_loss: 0.1494 - val_acc: 0.9521 - lr: 1.0000e-09\n","Epoch 40/40\n","120/120 [==============================] - ETA: 0s - loss: 0.0606 - acc: 0.9844\n","Epoch 40: val_acc did not improve from 0.96667\n","120/120 [==============================] - 12s 97ms/step - loss: 0.0606 - acc: 0.9844 - val_loss: 0.1494 - val_acc: 0.9521 - lr: 1.0000e-09\n"]}],"source":["#optimiramo jos broj neuorona u dodanom poptuno povezanom sloju\n","for ns in [128, 512]:\n","  print('Number of neurons: {0}\\n'.format(ns))\n","\n","  model_vgg16 = VGG16(\n","  input_shape=(200, 200, 3),\n","  include_top=False,\n","  weights='imagenet'\n","  )\n","\n","  for layer in model_vgg16.layers:\n","      layer.trainable = False\n","\n","  x = layers.Flatten()(model_vgg16.output)\n","  x = layers.Dropout(0.25)(x)\n","\n","  x = layers.Dense(units=ns, activation=\"relu\")(x)\n","  x = layers.Dense(units=1, activation=\"sigmoid\")(x)\n","\n","  model = tf.keras.Model(model_vgg16.input, x)\n","\n","  model.compile(\n","      optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3),\n","      loss=tf.keras.losses.BinaryCrossentropy(),\n","      metrics = ['acc']\n","  )\n","\n","  vgg = model.fit(x=train_x, y=y_train, \n","                  validation_data=(validation_x, y_validation),\n","                  batch_size=16,\n","                  epochs=40, \n","                  verbose=1, \n","                  callbacks=[reduce_lr, checkpoint_callback])"]},{"cell_type":"markdown","metadata":{"id":"VLfkQjxUBSZ1"},"source":["Najbolji rezultat koji smo dobili što se tiče accuracy-a, iznosi 96.996%\n","na validation setu."]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"896c2daa591989fc05a86cfdf5bf43ebcfd0edb421b3caf943f5a03fbbb816d2"}}},"nbformat":4,"nbformat_minor":0}
